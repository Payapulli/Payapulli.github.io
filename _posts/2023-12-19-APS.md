---
title: "Tree-Based Methods: Analyzing APS Failure Data with Advanced Machine Learning Techniques"
date: 2023-12-19
categories:
  - Data Science
---

This project revolves around the analysis of the APS Failure dataset from Scania Trucks, focusing on implementing tree-based methods for classification. The dataset, rich in attributes and challenges, offers an excellent opportunity to delve into techniques like Random Forest, XGBoost, and addressing class imbalances.


![Alt text for image](/assets/images/scania-trucks.jpeg)

<!--more-->

## Data Preparation and Exploration
### Dataset Acquisition and Preprocessing
- **Data Download**: Retrieving the APS Failure data, comprising 60,000 rows with 171 columns.
- **Handling Missing Values**: Researching and applying techniques to manage significant missing values in the dataset.

### Feature Analysis
- **Coefficient of Variation**: Calculating the CV for each of the 170 features.
- **Correlation Matrix**: Creating a matrix to understand the interdependencies between features.
- **Feature Visualization**: Selecting a subset of features with the highest CV for scatter and box plot visualization, aiding in assessing feature significance.

### Imbalance Assessment
- **Data Balance Analysis**: Determining the proportion of positive and negative instances to evaluate dataset balance.

## Random Forest Classification
### Initial Model Training
- **Model Training**: Developing a random forest model without addressing class imbalance.
- **Model Evaluation**: Assessing the model using confusion matrix, ROC, AUC, and misclassification rates for both training and test sets. Calculating the Out of Bag error estimate and comparing it with the test error.

### Addressing Class Imbalance
- **Research on Imbalance Handling**: Investigating how class imbalance is managed in random forests.
- **Imbalance Compensation**: Re-training the random forest with class imbalance compensation and comparing the results to the initial model.

## Advanced Tree-Based Techniques
### XGBoost and Model Trees
- **Model Tree Training**: Implementing an XGBoost model tree, using L1-penalized logistic regression at each node. 
- **Error Estimation**: Employing different cross-validation methods (5-fold, 10-fold, and leave-one-out) to estimate model error and comparing it with test error.
- **Model Metrics**: Reporting the Confusion Matrix, ROC, and AUC for both training and test sets.

### SMOTE for Class Imbalance
- **SMOTE Preprocessing**: Applying Synthetic Minority Over-sampling Technique (SMOTE) to address class imbalance.
- **Model Re-training**: Training the XGBoost model with L1-penalized logistic regression on the pre-processed data and repeating the error estimation and comparison.

[View Jupyter Notebook](https://nbviewer.org/github/Payapulli/Payapulli.github.io/blob/main/jupyter-notebooks/aps-random-forest.ipynb) | 
[View Project on GitHub](https://github.com/DSCI-552/homework-6-Payapulli) |
[View Dataset](https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks)